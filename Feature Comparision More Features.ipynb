{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e50663da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04d48047",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tejas\\AppData\\Local\\Temp\\ipykernel_16172\\157375421.py:1: DtypeWarning: Columns (1,9,10,11,12,13,15,17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_ncc = pd.read_csv(\"./ncc.binetflow\")\n",
      "C:\\Users\\tejas\\AppData\\Local\\Temp\\ipykernel_16172\\157375421.py:4: DtypeWarning: Columns (9,10,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_iot = pd.read_csv(\"./iot23.csv\").sample(25000)\n",
      "C:\\Users\\tejas\\AppData\\Local\\Temp\\ipykernel_16172\\157375421.py:5: DtypeWarning: Columns (5,8,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_ctu = pd.read_csv(\"./ctu.csv\").sample(25000)\n"
     ]
    }
   ],
   "source": [
    "df_ncc = pd.read_csv(\"./ncc.binetflow\")\n",
    "df_ncc=df_ncc[~df_ncc['Label'].str.contains(\"Background\", case=False, na=False)]\n",
    "df_ncc = df_ncc.sample(25000)\n",
    "df_iot = pd.read_csv(\"./iot23.csv\").sample(25000)\n",
    "df_ctu = pd.read_csv(\"./ctu.csv\").sample(25000)\n",
    "df_ctu=df_ctu[~df_ctu['Label'].str.contains(\"Background\", case=False, na=False)]\n",
    "df_ctu = df_ctu.sample(25000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b5c78b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iot['ActivityLabel'] = df_iot['label'].apply(lambda x: 0 if x == 'Benign' else 1)\n",
    "df_iot = df_iot.drop(columns=['label'])\n",
    "df_ctu['ActivityLabel'] = df_ctu['BOTNET'].apply(lambda x: 0 if x == 0 else 1)\n",
    "df_ctu = df_ctu.drop(columns=['BOTNET'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bda2cde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import RFE, SelectKBest, mutual_info_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25fc37b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_additional_graph_metrics(G):\n",
    "    # Calculate in-degree and out-degree\n",
    "    in_degree = dict(G.in_degree())\n",
    "    out_degree = dict(G.out_degree())\n",
    "\n",
    "    # Calculate eigenvector centrality\n",
    "    eigenvector_centrality = nx.eigenvector_centrality_numpy(G)\n",
    "\n",
    "    # Calculate betweenness centrality\n",
    "    betweenness_centrality = nx.betweenness_centrality(G)\n",
    "\n",
    "    return in_degree, out_degree, eigenvector_centrality, betweenness_centrality\n",
    "\n",
    "\n",
    "def convert_categorical_to_numeric(df):\n",
    "    le = LabelEncoder()\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == 'object' or df[column].dtype.name == 'category':\n",
    "            df[column] = le.fit_transform(df[column])\n",
    "    return df\n",
    "\n",
    "def convert_categorical_to_numeric(df):\n",
    "    le = LabelEncoder()\n",
    "    encoding_maps = {}\n",
    "    for column in df.columns:\n",
    "        if column == 'SrcAddr' or column == 'DstAddr':\n",
    "            if df[column].dtype == 'object' or df[column].dtype.name == 'category':\n",
    "                df[column] = le.fit_transform(df[column])\n",
    "                encoding_maps[column] = dict(zip(le.transform(le.classes_), le.classes_))\n",
    "        else:\n",
    "            if df[column].dtype == 'object' or df[column].dtype.name == 'category':\n",
    "                df[column] = df[column].astype(str)\n",
    "                df[column] = le.fit_transform(df[column])\n",
    "    return df, encoding_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e72e4c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "def feature_selection_vif(dataset, srcLabel, dstLabel, alpha=0.005, vif_threshold=20):\n",
    "    # Load and clean the dataset\n",
    "    df = dataset\n",
    "    df = df.drop_duplicates()\n",
    "    df = df.dropna()\n",
    "    \n",
    "    df['ActivityLabel'] = df['ActivityLabel'].apply(lambda x: 0 if x == 0 else 1)\n",
    "\n",
    "    # Convert non-numeric features to numeric\n",
    "    df, maps = convert_categorical_to_numeric(df)\n",
    "    \n",
    "    # Create the graph from IPs\n",
    "    ips = df[[srcLabel, dstLabel]]\n",
    "    G = nx.DiGraph()\n",
    "    for _, row in ips.iterrows():\n",
    "        G.add_edge(row[srcLabel], row[dstLabel])\n",
    "\n",
    "    # Calculate centrality metrics\n",
    "    degree_centrality = nx.degree_centrality(G)\n",
    "    closeness_centrality = nx.closeness_centrality(G)\n",
    "    betweenness_centrality = nx.betweenness_centrality(G)\n",
    "    eigenvector_centrality = nx.eigenvector_centrality_numpy(G)\n",
    "    in_degree_centrality = dict(G.in_degree())\n",
    "    out_degree_centrality = dict(G.out_degree())\n",
    "\n",
    "    def refined_normalize(metric):\n",
    "        values = np.array(list(metric.values()))\n",
    "        if len(values) == 0 or values.max() == values.min():\n",
    "            return dict(zip(metric.keys(), values))\n",
    "        percentiles = np.percentile(values, np.linspace(0, 100, 101))\n",
    "        normalized_values = np.interp(values, percentiles, np.linspace(0, 1, 101))\n",
    "        return dict(zip(metric.keys(), normalized_values))\n",
    "\n",
    "    degree_centrality_norm = refined_normalize(degree_centrality)\n",
    "    closeness_centrality_norm = refined_normalize(closeness_centrality)\n",
    "    betweenness_centrality_norm = refined_normalize(betweenness_centrality)\n",
    "    eigenvector_centrality_norm = refined_normalize(eigenvector_centrality)\n",
    "    in_degree_centrality_norm = refined_normalize(in_degree_centrality)\n",
    "    out_degree_centrality_norm = refined_normalize(out_degree_centrality)\n",
    "\n",
    "    # Compute Composite Node Importance (CNI)\n",
    "    cni_scores = {}\n",
    "    for node in G.nodes():\n",
    "        cni_scores[node] = (degree_centrality_norm.get(node, 0) +\n",
    "                            closeness_centrality_norm.get(node, 0) +\n",
    "                            betweenness_centrality_norm.get(node, 0)) / 3\n",
    "\n",
    "    # Add CNI scores and other metrics to the dataset\n",
    "    dataset_with_metrics = df.copy()\n",
    "    dataset_with_metrics['orig_h_CNI'] = dataset_with_metrics[srcLabel].map(cni_scores)\n",
    "    dataset_with_metrics['resp_h_CNI'] = dataset_with_metrics[dstLabel].map(cni_scores)\n",
    "    dataset_with_metrics['average_CNI'] = dataset_with_metrics[['orig_h_CNI', 'resp_h_CNI']].mean(axis=1)\n",
    "\n",
    "    dataset_with_metrics['orig_degree'] = dataset_with_metrics[srcLabel].map(degree_centrality_norm)\n",
    "    dataset_with_metrics['resp_degree'] = dataset_with_metrics[dstLabel].map(degree_centrality_norm)\n",
    "    dataset_with_metrics['orig_closeness'] = dataset_with_metrics[srcLabel].map(closeness_centrality_norm)\n",
    "    dataset_with_metrics['resp_closeness'] = dataset_with_metrics[dstLabel].map(closeness_centrality_norm)\n",
    "    dataset_with_metrics['orig_betweenness'] = dataset_with_metrics[srcLabel].map(betweenness_centrality_norm)\n",
    "    dataset_with_metrics['resp_betweenness'] = dataset_with_metrics[dstLabel].map(betweenness_centrality_norm)\n",
    "    dataset_with_metrics['orig_eigenvector'] = dataset_with_metrics[srcLabel].map(eigenvector_centrality_norm)\n",
    "    dataset_with_metrics['resp_eigenvector'] = dataset_with_metrics[dstLabel].map(eigenvector_centrality_norm)\n",
    "    dataset_with_metrics['orig_in_degree'] = dataset_with_metrics[srcLabel].map(in_degree_centrality_norm)\n",
    "    dataset_with_metrics['resp_in_degree'] = dataset_with_metrics[dstLabel].map(in_degree_centrality_norm)\n",
    "    dataset_with_metrics['orig_out_degree'] = dataset_with_metrics[srcLabel].map(out_degree_centrality_norm)\n",
    "    dataset_with_metrics['resp_out_degree'] = dataset_with_metrics[dstLabel].map(out_degree_centrality_norm)\n",
    "\n",
    "    # Separate features for VIF calculation\n",
    "    df_final = dataset_with_metrics.drop([\"orig_h_CNI\", \"resp_h_CNI\"], axis=1)\n",
    "    \n",
    "    # Calculate traditional VIF\n",
    "    def calculate_vif(df):\n",
    "        X = df.values\n",
    "        vif_scores = [variance_inflation_factor(X, i) for i in range(X.shape[1])]\n",
    "        vif_data = pd.DataFrame({'Feature': df.columns, 'Traditional_VIF': vif_scores})\n",
    "        return vif_data\n",
    "    start_time_1 = time()\n",
    "    vif_results = calculate_vif(df_final)\n",
    "    vif_time = time() - start_time_1\n",
    "    \n",
    "    vif_scores = vif_results\n",
    "\n",
    "    # Iterative VIF-based feature selection\n",
    "    features_to_remove = []\n",
    "    high_vif_features = vif_results[vif_results['Traditional_VIF'] > vif_threshold]['Feature'].tolist()\n",
    "    while high_vif_features:\n",
    "        feature_to_remove = high_vif_features[0]\n",
    "        features_to_remove.append(feature_to_remove)\n",
    "        vif_results = vif_results[vif_results['Feature'] != feature_to_remove]\n",
    "        remaining_features = vif_results['Feature'].tolist()\n",
    "        X_subset = df_final[remaining_features]\n",
    "        vif_results['Traditional_VIF'] = [variance_inflation_factor(X_subset.values, i) for i in range(X_subset.shape[1])]\n",
    "        high_vif_features = vif_results[vif_results['Traditional_VIF'] > vif_threshold]['Feature'].tolist()\n",
    "\n",
    "    # Calculate Modified VIF\n",
    "    def calculate_modified_vif(X, alpha):\n",
    "        features = X.columns\n",
    "        \n",
    "        feat_list = features.tolist()\n",
    "        feat_list.remove(\"average_CNI\")\n",
    "        features = pd.Index(feat_list)\n",
    "        mvif_data = []\n",
    "        for feature in features:\n",
    "            predictors = [feat for feat in features if feat != feature]\n",
    "            model = LinearRegression().fit(X[predictors], X[feature])\n",
    "            r_squared = model.score(X[predictors], X[feature])\n",
    "            average_cni_mean = dataset_with_metrics['average_CNI'].mean()\n",
    "            # Normalizing the adjustment term\n",
    "            normalized_adjustment = (r_squared + alpha * average_cni_mean) / (1 + alpha * average_cni_mean)\n",
    "        \n",
    "        # Ensure the value inside the division is positive\n",
    "            if normalized_adjustment >= 1.0:\n",
    "                normalized_adjustment = 1.0 - 1e-6  # Adjust to avoid negative or zero denominator\n",
    "\n",
    "            modified_vif = 1 / (1 - normalized_adjustment)\n",
    "            mvif_data.append({'Feature': feature, 'Modified_VIF': modified_vif})\n",
    "        \n",
    "        return pd.DataFrame(mvif_data)\n",
    "    \n",
    "            \n",
    "\n",
    "    X = df_final\n",
    "    start_time_1 = time()\n",
    "    mvif_results = calculate_modified_vif(X, alpha)\n",
    "    mvif_time = time() - start_time_1\n",
    "\n",
    "    # Normalize MVIF values\n",
    "    mvif_values = mvif_results['Modified_VIF'].values\n",
    "    mvif_min, mvif_max = mvif_values.min(), mvif_values.max()\n",
    "    mvif_results['Normalized_Modified_VIF'] = (mvif_values - mvif_min) / (mvif_max - mvif_min)\n",
    "\n",
    "    final_vif_results = pd.merge(vif_scores, mvif_results, on='Feature')\n",
    "    selected_features = mvif_results[mvif_results['Modified_VIF'] < vif_threshold]['Feature'].tolist()\n",
    "\n",
    "    return df_final, final_vif_results,mvif_time,vif_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44dd1eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "def apply_pca_rfe_and_compare(df, final_vif_results, label_col='ActivityLabel', vif_threshold=10):\n",
    "    selected_features_vif = final_vif_results[final_vif_results['Traditional_VIF'] < vif_threshold]['Feature'].tolist()\n",
    "    selected_features_mvif = final_vif_results[final_vif_results['Modified_VIF'] < vif_threshold]['Feature'].tolist()\n",
    "    X_vif = df[selected_features_vif]\n",
    "    X_mvif = df[selected_features_mvif]\n",
    "    y = df[label_col]\n",
    "\n",
    "    # Apply PCA\n",
    "    start_time = time()\n",
    "    pca = PCA(n_components=0.95)  # Retain 95% of variance\n",
    "    X_pca = pca.fit_transform(df.drop(columns=[label_col]))\n",
    "    pca_time = time() - start_time\n",
    "\n",
    "    # Get PCA loadings and select top features\n",
    "    pca_loadings = pd.DataFrame(pca.components_.T, columns=[f'PC{i+1}' for i in range(pca.n_components_)], index=df.drop(columns=[label_col]).columns)\n",
    "    pca_selected_features = pca_loadings.abs().mean(axis=1).nlargest(10).index.tolist()  # Select top 10 features\n",
    "\n",
    "    # Apply RFE\n",
    "    start_time = time()\n",
    "    model = LogisticRegression(solver='liblinear')\n",
    "    rfe = RFE(model, n_features_to_select=10)\n",
    "    rfe.fit(df.drop(columns=[label_col]), y)\n",
    "    rfe_selected_features = df.drop(columns=[label_col]).columns[rfe.support_].tolist()\n",
    "    rfe_time = time() - start_time\n",
    "\n",
    "    # Compile the results\n",
    "    result = {\n",
    "        'VIF': selected_features_vif,\n",
    "        'CNI-VIF': selected_features_mvif,\n",
    "        'PCA': pca_selected_features,\n",
    "        'RFE': rfe_selected_features\n",
    "    }\n",
    "\n",
    "    # Return results and times\n",
    "    return result, pca_time, rfe_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee5a4b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, Flatten, MaxPooling1D\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "def create_ffnn(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='relu', input_shape=(input_shape,)))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def create_cnn(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(32, 3, activation='relu', input_shape=input_shape))\n",
    "    \n",
    "    # Ensure the input length is sufficient for pooling\n",
    "    if input_shape[0] >= 2:\n",
    "        model.add(MaxPooling1D(2))\n",
    "    \n",
    "    conv1_output_length = input_shape[0] - 2  # Since kernel size is 3\n",
    "    pool1_output_length = conv1_output_length // 2\n",
    "\n",
    "    # Check if the length is sufficient for another Conv1D and MaxPooling1D layer\n",
    "    if pool1_output_length >= 3:\n",
    "        model.add(Conv1D(64, 3, activation='relu'))\n",
    "        if pool1_output_length >= 6:  # Ensure the length is sufficient after another pooling\n",
    "            model.add(MaxPooling1D(2))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def evaluate_models(selection_result, df, label_col='ActivityLabel'):\n",
    "    models = {\n",
    "        'Logistic Regression': LogisticRegression(solver='liblinear'),\n",
    "        'Random Forest': RandomForestClassifier(),\n",
    "        'SVM': SVC(probability=True),\n",
    "        'Ensemble (Voting)': VotingClassifier(\n",
    "            estimators=[\n",
    "                ('lr', LogisticRegression(solver='liblinear')),\n",
    "                ('rf', RandomForestClassifier()),\n",
    "                ('svm', SVC(probability=True))\n",
    "            ], voting='soft'\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    results = {technique: {} for technique in selection_result.keys()}\n",
    "    \n",
    "    for technique, features in selection_result.items():\n",
    "        X = df[features]\n",
    "        y = df[label_col]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        for model_name, model in models.items():\n",
    "            start_time = time()\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            precision = precision_score(y_test, y_pred)\n",
    "            recall = recall_score(y_test, y_pred)\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "            computation_time = time() - start_time\n",
    "            \n",
    "            results[technique][model_name] = {\n",
    "                'Accuracy': accuracy,\n",
    "                'Precision': precision,\n",
    "                'Recall': recall,\n",
    "                'F1-Score': f1,\n",
    "                'Computation Time': computation_time\n",
    "            }\n",
    "        \n",
    "        start_time = time()\n",
    "        ffnn = create_ffnn(X_train.shape[1])\n",
    "        ffnn.fit(X_train, y_train, epochs=10, batch_size=32, verbose=0)\n",
    "        y_pred_ffnn = (ffnn.predict(X_test) > 0.5).astype(int).flatten()\n",
    "        accuracy_ffnn = accuracy_score(y_test, y_pred_ffnn)\n",
    "        precision_ffnn = precision_score(y_test, y_pred_ffnn)\n",
    "        recall_ffnn = recall_score(y_test, y_pred_ffnn)\n",
    "        f1_ffnn = f1_score(y_test, y_pred_ffnn)\n",
    "        computation_time_ffnn = time() - start_time\n",
    "        \n",
    "        results[technique]['FFNN'] = {\n",
    "            'Accuracy': accuracy_ffnn,\n",
    "            'Precision': precision_ffnn,\n",
    "            'Recall': recall_ffnn,\n",
    "            'F1-Score': f1_ffnn,\n",
    "            'Computation Time': computation_time_ffnn\n",
    "        }\n",
    "        \n",
    "        start_time = time()\n",
    "        X_train_cnn = np.expand_dims(X_train, axis=2)\n",
    "        X_test_cnn = np.expand_dims(X_test, axis=2)\n",
    "        input_shape = (X_train_cnn.shape[1], X_train_cnn.shape[2])\n",
    "        cnn = create_cnn(input_shape)\n",
    "        cnn.fit(X_train_cnn, y_train, epochs=10, batch_size=32, verbose=0)\n",
    "        y_pred_cnn = (cnn.predict(X_test_cnn) > 0.5).astype(int).flatten()\n",
    "        accuracy_cnn = accuracy_score(y_test, y_pred_cnn)\n",
    "        precision_cnn = precision_score(y_test, y_pred_cnn)\n",
    "        recall_cnn = recall_score(y_test, y_pred_cnn)\n",
    "        f1_cnn = f1_score(y_test, y_pred_cnn)\n",
    "        computation_time_cnn = time() - start_time\n",
    "        \n",
    "        results[technique]['CNN'] = {\n",
    "            'Accuracy': accuracy_cnn,\n",
    "            'Precision': precision_cnn,\n",
    "            'Recall': recall_cnn,\n",
    "            'F1-Score': f1_cnn,\n",
    "            'Computation Time': computation_time_cnn\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def plot_results(results, title):\n",
    "    plot_data = []\n",
    "    for technique, metrics in results.items():\n",
    "        for model_name, result in metrics.items():\n",
    "            plot_data.append({\n",
    "                'Technique': technique,\n",
    "                'Model': model_name,\n",
    "                'Accuracy': result['Accuracy'],\n",
    "                'Precision': result['Precision'],\n",
    "                'Recall': result['Recall'],\n",
    "                'F1-Score': result['F1-Score'],\n",
    "                'Computation Time': result['Computation Time']\n",
    "            })\n",
    "    plot_df = pd.DataFrame(plot_data)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x='Technique', y='Accuracy', hue='Model', data=plot_df)\n",
    "    plt.title(f'Model Accuracy by Feature Selection Technique for {title}')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Feature Selection Technique')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x='Technique', y='Precision', hue='Model', data=plot_df)\n",
    "    plt.title(f'Model Precision by Feature Selection Technique for {title}')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.xlabel('Feature Selection Technique')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x='Technique', y='Recall', hue='Model', data=plot_df)\n",
    "    plt.title(f'Model Recall by Feature Selection Technique for {title}')\n",
    "    plt.ylabel('Recall')\n",
    "    plt.xlabel('Feature Selection Technique')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x='Technique', y='F1-Score', hue='Model', data=plot_df)\n",
    "    plt.title(f'Model F1-Score by Feature Selection Technique for {title}')\n",
    "    plt.ylabel('F1-Score')\n",
    "    plt.xlabel('Feature Selection Technique')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x='Technique', y='Computation Time', hue='Model', data=plot_df)\n",
    "    plt.title(f'Model Computation Time by Feature Selection Technique for {title}')\n",
    "    plt.ylabel('Computation Time (seconds)')\n",
    "    plt.xlabel('Feature Selection Technique')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "\n",
    "def extract_data(data):\n",
    "    result = []\n",
    "    for feature_selection in data:\n",
    "        for model, metrics in data[feature_selection].items():\n",
    "            result.append([\n",
    "                feature_selection,\n",
    "                model,\n",
    "                metrics['Accuracy'],\n",
    "                metrics['Precision'],\n",
    "                metrics['Recall'],\n",
    "                metrics['F1-Score'],\n",
    "                metrics['Computation Time']\n",
    "            ])\n",
    "    return result\n",
    "\n",
    "def create_table(data):\n",
    "    df = pd.DataFrame(data, columns=[\n",
    "        'Feature Selection Technique',\n",
    "        'Model',\n",
    "        'Accuracy',\n",
    "        'Precision',\n",
    "        'Recall',\n",
    "        'F1-Score',\n",
    "        'Computation Time'\n",
    "    ])\n",
    "    return df\n",
    "\n",
    "def plot_times(times,dataset_label):\n",
    "    algorithms = ['VIF', 'CNI-VIF', 'PCA', 'RFE']\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(algorithms, times, marker='o', linestyle='-', color='b')\n",
    "    plt.xlabel('Algorithm')\n",
    "    plt.ylabel('Time (seconds)')\n",
    "    plt.title(f'Algorithm Execution Times for {dataset_label}')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03fdf5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_output(df,src_label,dst_label,dataset_name):\n",
    "    df_final,vif_comparison_table,mvif_time,vif_time = feature_selection_vif(df,src_label,dst_label)\n",
    "    print(vif_comparison_table)\n",
    "\n",
    "    selection_result,pca_time,rfe_time = apply_pca_rfe_and_compare(df_final, vif_comparison_table)\n",
    "    print(selection_result)\n",
    "\n",
    "    plot_times([vif_time,mvif_time,pca_time,rfe_time],dataset_name)\n",
    "    print(f\"PCA:{pca_time} RFE:{rfe_time} MVIF:{mvif_time} VIF:{vif_time}\")\n",
    "\n",
    "    model_results = evaluate_models(selection_result, df_final)\n",
    "    plot_results(model_results,dataset_name)\n",
    "    extracted_data = extract_data(model_results)\n",
    "    table = create_table(extracted_data)\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4c72bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tejas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1785: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "C:\\Users\\tejas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:197: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  vif = 1. / (1. - r_squared_i)\n",
      "C:\\Users\\tejas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1785: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "C:\\Users\\tejas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:197: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  vif = 1. / (1. - r_squared_i)\n",
      "C:\\Users\\tejas\\AppData\\Local\\Temp\\ipykernel_16172\\1891372090.py:97: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vif_results['Traditional_VIF'] = [variance_inflation_factor(X_subset.values, i) for i in range(X_subset.shape[1])]\n",
      "C:\\Users\\tejas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1785: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "C:\\Users\\tejas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:197: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  vif = 1. / (1. - r_squared_i)\n",
      "C:\\Users\\tejas\\AppData\\Local\\Temp\\ipykernel_16172\\1891372090.py:97: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vif_results['Traditional_VIF'] = [variance_inflation_factor(X_subset.values, i) for i in range(X_subset.shape[1])]\n",
      "C:\\Users\\tejas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1785: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "C:\\Users\\tejas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:197: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  vif = 1. / (1. - r_squared_i)\n",
      "C:\\Users\\tejas\\AppData\\Local\\Temp\\ipykernel_16172\\1891372090.py:97: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vif_results['Traditional_VIF'] = [variance_inflation_factor(X_subset.values, i) for i in range(X_subset.shape[1])]\n",
      "C:\\Users\\tejas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1785: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "C:\\Users\\tejas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:197: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  vif = 1. / (1. - r_squared_i)\n",
      "C:\\Users\\tejas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1785: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "C:\\Users\\tejas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:197: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  vif = 1. / (1. - r_squared_i)\n",
      "C:\\Users\\tejas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1785: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "C:\\Users\\tejas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1785: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "C:\\Users\\tejas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1785: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "C:\\Users\\tejas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1785: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "C:\\Users\\tejas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1785: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "C:\\Users\\tejas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1785: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "C:\\Users\\tejas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1785: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "C:\\Users\\tejas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1785: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "C:\\Users\\tejas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1785: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "C:\\Users\\tejas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1785: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "C:\\Users\\tejas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1785: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return 1 - self.ssr/self.uncentered_tss\n",
      "C:\\Users\\tejas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1785: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return 1 - self.ssr/self.uncentered_tss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Feature  Traditional_VIF   Modified_VIF  Normalized_Modified_VIF\n",
      "0          StartTime     4.029644e+00       1.034775             0.000000e+00\n",
      "1                Dur     6.940475e+00       2.019350             9.845753e-07\n",
      "2              Proto     6.567847e+01       7.422668             6.387899e-06\n",
      "3            SrcAddr     6.433280e+01      13.929836             1.289507e-05\n",
      "4              Sport     3.989619e+00       2.141010             1.106236e-06\n",
      "5                Dir     1.038044e+01       7.851568             6.816800e-06\n",
      "6            DstAddr     4.612092e+00       1.550044             5.152692e-07\n",
      "7              Dport     3.023846e+01       1.630578             5.958029e-07\n",
      "8              State     4.267037e+00       1.960364             9.255895e-07\n",
      "9               sTos              NaN  999999.999971             1.000000e+00\n",
      "10              dTos              NaN  999999.999971             1.000000e+00\n",
      "11           TotPkts     3.792792e+00       1.245373             2.105982e-07\n",
      "12          TotBytes     5.375387e+00       1.142891             1.081158e-07\n",
      "13          SrcBytes     7.498409e+00       1.361915             3.271398e-07\n",
      "14             Label     3.170447e+01       3.592152             2.557380e-06\n",
      "15     ActivityLabel     8.356937e+01      21.641919             2.060716e-05\n",
      "16        BotnetName     1.389463e+01       4.429479             3.394707e-06\n",
      "17          SensorId     4.053290e+00       1.181648             1.468730e-07\n",
      "18       orig_degree              inf       3.485282             2.450509e-06\n",
      "19       resp_degree              inf     423.312917             4.222786e-04\n",
      "20    orig_closeness              inf       5.076102             4.041331e-06\n",
      "21    resp_closeness              inf      26.405883             2.537113e-05\n",
      "22  orig_betweenness              inf       4.390236             3.355464e-06\n",
      "23  resp_betweenness              inf       3.866419             2.831647e-06\n",
      "24  orig_eigenvector     1.269831e+02      14.134910             1.310015e-05\n",
      "25  resp_eigenvector     5.066050e+02      27.700254             2.666551e-05\n",
      "26    orig_in_degree     4.779877e+03      25.954677             2.491993e-05\n",
      "27    resp_in_degree     1.374076e+04     432.862020             4.318277e-04\n",
      "28   orig_out_degree     8.985032e+05      26.824633             2.578988e-05\n",
      "29   resp_out_degree     2.631054e+06      13.081576             1.204681e-05\n",
      "{'VIF': ['StartTime', 'Dur', 'Sport', 'DstAddr', 'State', 'TotPkts', 'TotBytes', 'SrcBytes', 'SensorId'], 'CNI-VIF': ['StartTime', 'Dur', 'Proto', 'Sport', 'Dir', 'DstAddr', 'Dport', 'State', 'TotPkts', 'TotBytes', 'SrcBytes', 'Label', 'BotnetName', 'SensorId', 'orig_degree', 'orig_closeness', 'orig_betweenness', 'resp_betweenness'], 'PCA': ['Dur', 'Sport', 'StartTime', 'TotBytes', 'SrcBytes', 'DstAddr', 'TotPkts', 'Label', 'State', 'Dport'], 'RFE': ['BotnetName', 'average_CNI', 'orig_degree', 'resp_degree', 'orig_betweenness', 'resp_betweenness', 'orig_eigenvector', 'resp_in_degree', 'orig_out_degree', 'resp_out_degree']}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA:0.050995588302612305 RFE:6.119175672531128 MVIF:1.7482261657714844 VIF:2.4207546710968018\n",
      "201/201 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "table0 = final_output(df_ncc,\"SrcAddr\",\"DstAddr\",\"NCC Dataset\")\n",
    "table0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f5f880",
   "metadata": {},
   "outputs": [],
   "source": [
    "table1 = final_output(df_iot,\"id.orig_h\",\"id.resp_h\",\"IOT 23\")\n",
    "table1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83ba8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "table2 = final_output(df_ctu,\"SrcAddr\",\"DstAddr\",\"CTU Dataset\")\n",
    "table2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c8a316",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f16e8ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
